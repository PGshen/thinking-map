# AI 编程工具的真实体验：从期待到现实的落差与适应

> 本文是“AI 编程实践：从想法到产品”系列的第二篇。聚焦我在 Cursor、Copilot、Trae AI 等工具中的真实使用体验：哪些地方好用、哪些地方踩坑、如何调整人机协作模式，以及可落地的提示工程与代码审查方法。

## 初次接触：震撼、困惑与认知失衡
最初被官方演示与自媒体的“智能”“效率”震撼，冷静后随之而来的是焦虑：我会不会很快被替代？于是我开始系统地尝试这些工具。在 demo 项目里，它们确实效果惊艳；一旦落到真实复杂项目，问题也迅速暴露——理解偏差、上下文失真、隐性复杂度上升。

第一次把 AI 编程工具用到正经项目里，体验是复杂的：
- 代码自动补全的惊喜：类型推断、样板代码、测试样例草拟都更快；
- 面对建议的犹豫：当 AI 给出“看似合理”的重构或架构建议时，很难迅速判断是否该接收；
- 依赖带来的惰性：一旦习惯“AI 先写”，容易忽略系统性思考与边界条件；
- 失去对代码的掌控：如果AI写了代码，没有review，照单全收，很容易后续总感觉无从下手。

我很快意识到：就目前而言，这些工具是“加速器”，不是“替代品”。当你清楚要到达哪儿，它们让你更快；当你还没想清楚，它们会把你带到更远的歧路。

## 工具选择的迷茫期：为何最终采用多工具组合

我试过多款工具，最后形成了组合拳：
- Copilot：写局部代码时的轻量补全，减少机械劳动；
- Cursor：在文件内/小范围的生成、重构与“对话式变更”，对局部任务很高效；
- Trae AI：做项目级语义检索、跨文件理解与联动修改，更适合“大图景”的变更。

这套组合的核心逻辑是“分工”：
- 局部 → 用补全/生成；
- 模块级 → 用对话式重构；
- 项目级 → 用语义搜索+结构化改造计划。

## 利与弊：工具好用在哪里，不好用在哪里

整体评估：
- 优点：提升开发速度、覆盖知识盲区、降低重复劳动成本；
- 风险：理解偏差、隐性复杂度上升、上下文失真导致看不见的 bug。

好用的场景：
- 重复性或模板化代码（DTO、校验逻辑、Hook 模板、测试样例草拟）；
- 跨文件检索与重构建议（统一接口命名、提取通用组件或工具函数）；
- 类型补全与边界条件枚举（TS 严格模式下尤为明显）。

不好用的场景：
- 复杂业务语义与领域规则（缺真实场景/约束会误导实现）；
- 核心架构设计与关键抽象（需要明确的约束与权衡）；
- 安全与合规逻辑（需强一致性与可审计性，AI建议多半不够严谨）。

## 使用过程中的真实问题：代码质量与上下文理解

两个最常见的痛点：
- 质量参差不齐：AI 为了“看起来正确”会牺牲边界条件与错误处理，容易埋隐患；
- 上下文理解有限：项目复杂后，工具容易忽略已有约束（命名规则、状态管理模式、API 约定）。

我用了两种方法缓解：
- 规则显式化：把项目规则写进可检索的结构化文档（如 docs/ 下的前端/后端规范），并在提示里引用；
- 约束前置：先要求 AI 复述约束与目标，再让它写代码。若复述不到位，立即修正而非继续生成。

## 语义搜索的强大与局限：如何用好 Trae

语义搜索让“找得到”变得容易，但“理解对不对”仍是难点：
- 强项：快速定位关键代码、梳理调用链、发现隐式关系；
- 局限：对相似概念/重名符号的区分度不够，跨边界的重构建议需谨慎。

实践策略：
- 多轮搜索：用不同关键词/表述重复检索，同步验证结果一致性；
- 先读再改：拿到候选片段后先通读上下文，明确依赖与边界，再发起修改；
- 小步提交：跨文件变更按功能切块推进，避免“全量大改”带来的回滚成本。

## 人机协作模式：提示工程与生成策略

学习曲线的关键在于“让 AI 理解你的真实意图”。以下是我形成的几条实用规则。

- 意图对齐三步法：
  - 背景：给出任务上下文（模块、边界、现状问题）；
  - 目标：明确输出形态（接口、类型、文件、测试）；
  - 约束：列出必须遵守的项目规则（命名、错误处理、状态管理）。

- 生成策略：
  - 先理解后动手：要求 AI 复述目标与约束；
  - 分模块生成：把复杂任务拆成“可验收”的小块；
  - 旁路校验：生成后让它列出“可能的风险与边界条件”，用于自审。

- 调试协作：
  - 明确问题复述：提供错误日志、触发条件、期望 vs 观察；
  - 根因定位：要求输出“最可能原因的排序”与“可验证实验”；
  - 最小修复：优先选择“对现有架构侵入最小”的修复方案。

附上一个我常用的提示模板（可按需调整）：

```
[背景]
- 项目：Next.js 15 + TypeScript 严格模式 + Zustand + ReactFlow
- 目标：实现/修改 X 功能；保持现有目录与命名规范

[输出]
- 需要的文件/函数
- TypeScript 类型/接口
- 关键边界条件与错误处理
- 简短的测试样例或使用示例

[约束]
- 遵循 docs/frontend-*.md 的组件与状态管理模式
- 使用 shadcn/ui 与 Tailwind；toast 用 sonner
- API 调用遵循 src/api 模式；SSE 参照 use-sse-connection
```

## 代码审查的新挑战：如何审 AI 生成的代码

AI 生成的代码往往“看起来合理”，但细节处容易失真。我采用这套审查清单：
- 意图一致：实现是否真正服务于需求与约束；
- 类型严谨：TS 类型是否覆盖边界；是否隐式 any；
- 状态最小化：Zustand 选择器是否避免不必要的重渲染；
- 错误处理：是否有合理的错误边界与用户提示（sonner）；
- 一致性：命名、目录、导入路径是否符合项目规范；
- 回归影响：变更是否影响相邻模块；是否需要同步调整测试或文档。

## 效率与新问题的平衡：何时用、何时不用

效率提升是真实的，但应选择性使用：
- 最适合 AI 辅助的任务：样板代码、跨文件检索、类型补全、简单测试样例；
- 不适合的任务：架构设计、跨领域复杂业务、强一致性安全逻辑；
- 仍需人工完成的工作：边界条件设计、异常路径推演、性能与资源评估、最终的审查与决策。

随时间推移，一个新的能力需求也变得明显：
- 提示工程能力（结构化描述、约束管理、上下文引用）；
- 代码审查能力（识别隐性复杂度、统一风格）；
- 架构思维（把生成结果纳入长期演进的框架）。

## 关键收获：实用策略与可复用方法

- 把工具当“加速器”，而非“自动驾驶”；
- 用文档做“上下文工程”，把约束显式化并可检索；
- 语义搜索多轮验证，跨文件变更小步提交；
- 生成前先对齐意图与约束，生成后做旁路校验；
- 建立适配项目的审查清单，避免“看起来正确”的陷阱。

## 下一篇预告

第三篇将进入系统架构设计实践：为何选择 eino，如何在 Multi Agent 协作中落地 ReAct 模式，以及这套架构在 ThinkingMap 项目中的真实挑战与妥协。