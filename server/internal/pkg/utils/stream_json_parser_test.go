package utils

import (
	"fmt"
	"strings"
	"testing"
	"time"
)

func TestSimplePathMatcher(t *testing.T) {
	matcher := NewSimplePathMatcher()

	// æµ‹è¯•è·¯å¾„è§£æ
	tests := []struct {
		pattern  string
		expected []interface{}
	}{
		{"$", []interface{}{"$"}},
		{"users[*].name", []interface{}{"users", "*", "name"}},
		{"data.items[0].value", []interface{}{"data", "items", 0, "value"}},
		{"response.content", []interface{}{"response", "content"}},
	}

	for _, test := range tests {
		result := matcher.parsePath(test.pattern)
		if len(result) != len(test.expected) {
			t.Errorf("Pattern %s: expected length %d, got %d", test.pattern, len(test.expected), len(result))
			continue
		}

		for i, expected := range test.expected {
			if result[i] != expected {
				t.Errorf("Pattern %s: expected %v at index %d, got %v", test.pattern, expected, i, result[i])
			}
		}
	}
}

func TestStreamingJsonParser(t *testing.T) {
	matcher := NewSimplePathMatcher()
	results := make(map[string]interface{})

	// æ³¨å†Œè·¯å¾„åŒ¹é…å›è°ƒ
	matcher.On("name", func(value interface{}, path []interface{}) {
		results["name"] = value
		fmt.Printf("Found name: %v at path: %v\n", value, path)
	})

	matcher.On("users[*].email", func(value interface{}, path []interface{}) {
		results["email"] = value
		fmt.Printf("Found email: %v at path: %v\n", value, path)
	})

	parser := NewStreamingJsonParser(matcher, false, false)

	// æµ‹è¯•ç®€å•JSON
	jsonData := `{"name": "John", "age": 30, "users": [{"email": "john@example.com"}]}`

	err := parser.Write(jsonData)
	if err != nil {
		t.Fatalf("Failed to parse JSON: %v", err)
	}

	err = parser.End()
	if err != nil {
		t.Fatalf("Failed to end parsing: %v", err)
	}

	// éªŒè¯ç»“æœ
	if results["name"] != "John" {
		t.Errorf("Expected name to be 'John', got %v", results["name"])
	}

	if results["email"] != "john@example.com" {
		t.Errorf("Expected email to be 'john@example.com', got %v", results["email"])
	}
}

func TestStreamingJsonParserRealtime(t *testing.T) {
	matcher := NewSimplePathMatcher()
	callbackCount := 0

	// æ³¨å†Œå®æ—¶å›è°ƒ
	matcher.On("message", func(value interface{}, path []interface{}) {
		callbackCount++
		fmt.Printf("Realtime callback %d: %v\n", callbackCount, value)
	})

	parser := NewStreamingJsonParser(matcher, true, false)

	// æ¨¡æ‹Ÿæµå¼è¾“å…¥
	chunks := []string{
		`{"message": "Hel`,
		`lo Wor`,
		`ld"}`}

	for _, chunk := range chunks {
		err := parser.Write(chunk)
		if err != nil {
			t.Fatalf("Failed to parse chunk '%s': %v", chunk, err)
		}
	}

	err := parser.End()
	if err != nil {
		t.Fatalf("Failed to end parsing: %v", err)
	}

	// åœ¨å®æ—¶æ¨¡å¼ä¸‹ï¼Œåº”è¯¥æœ‰å¤šæ¬¡å›è°ƒ
	if callbackCount == 0 {
		t.Error("Expected at least one callback in realtime mode")
	}

	fmt.Printf("Total callbacks in realtime mode: %d\n", callbackCount)
}

func TestComplexJsonStructure(t *testing.T) {
	matcher := NewSimplePathMatcher()
	results := make([]interface{}, 0)

	// åŒ¹é…æ•°ç»„ä¸­çš„æ‰€æœ‰é¡¹ç›®
	matcher.On("data.items[*].value", func(value interface{}, path []interface{}) {
		results = append(results, value)
		fmt.Printf("Found item value: %v at path: %v\n", value, path)
	})

	parser := NewStreamingJsonParser(matcher, false, false)

	// å¤æ‚çš„JSONç»“æ„
	jsonData := `{
		"data": {
			"items": [
				{"value": "first", "id": 1},
				{"value": "second", "id": 2},
				{"value": "third", "id": 3}
			]
		},
		"meta": {"count": 3}
	}`

	err := parser.Write(jsonData)
	if err != nil {
		t.Fatalf("Failed to parse complex JSON: %v", err)
	}

	err = parser.End()
	if err != nil {
		t.Fatalf("Failed to end parsing: %v", err)
	}

	// éªŒè¯ç»“æœ
	expectedValues := []string{"first", "second", "third"}
	if len(results) != len(expectedValues) {
		t.Errorf("Expected %d results, got %d", len(expectedValues), len(results))
	}

	for i, expected := range expectedValues {
		if i < len(results) && results[i] != expected {
			t.Errorf("Expected result[%d] to be '%s', got %v", i, expected, results[i])
		}
	}
}

func TestErrorHandling(t *testing.T) {
	matcher := NewSimplePathMatcher()
	parser := NewStreamingJsonParser(matcher, false, false)

	// æµ‹è¯•æ— æ•ˆJSON
	invalidJson := `{"name": "test", "invalid": }`
	err := parser.Write(invalidJson)
	if err == nil {
		t.Error("Expected error for invalid JSON, but got none")
	}
}

func TestStreamingJsonParserIncremental(t *testing.T) {
	tests := []struct {
		name        string
		input       []string // åˆ†å—è¾“å…¥
		incremental bool
		expected    []string // æœŸæœ›çš„å›è°ƒç»“æœ
	}{
		{
			name:        "incremental mode - complete values",
			input:       []string{`{"thought":"First part"}`, `{"thought":"Second part"}`, `{"thought":"Third part"}`},
			incremental: true,
			expected:    []string{"First part", "Second part", "Third part"},
		},
		{
			name:        "cumulative mode - complete values",
			input:       []string{`{"thought":"First part"}`, `{"thought":"Second part"}`, `{"thought":"Third part"}`},
			incremental: false,
			expected:    []string{"First part", "Second part", "Third part"},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			var results []string
			matcher := NewSimplePathMatcher()
			matcher.On("thought", func(value interface{}, path []interface{}) {
				if str, ok := value.(string); ok {
					results = append(results, str)
				}
			})

			parser := NewStreamingJsonParser(matcher, false, tt.incremental) // éå®æ—¶æ¨¡å¼

			for _, chunk := range tt.input {
				parser.Reset() // æ¯ä¸ªJSONé‡ç½®è§£æå™¨
				if err := parser.Write(chunk); err != nil {
					t.Fatalf("Failed to write chunk: %v", err)
				}
				if err := parser.End(); err != nil {
					t.Fatalf("Failed to end parsing: %v", err)
				}
			}

			if len(results) != len(tt.expected) {
				t.Fatalf("Expected %d results, got %d: %v", len(tt.expected), len(results), results)
			}

			for i, expected := range tt.expected {
				if results[i] != expected {
					t.Errorf("Result %d: expected %q, got %q", i, expected, results[i])
				}
			}
		})
	}
}

func TestStreamingJsonParserRealtimeIncremental(t *testing.T) {
	// æµ‹è¯•å®æ—¶æ¨¡å¼ä¸‹çš„å¢é‡è§£æ
	var incrementalResults []string
	matcher1 := NewSimplePathMatcher()
	matcher1.On("thought", func(value interface{}, path []interface{}) {
		if str, ok := value.(string); ok {
			incrementalResults = append(incrementalResults, str)
			t.Logf("Incremental result: %q", str)
		}
	})

	// æµ‹è¯•å¢é‡æ¨¡å¼
	parser := NewStreamingJsonParser(matcher1, true, true)

	// æ¨¡æ‹Ÿæµå¼è¾“å…¥ - åœ¨å­—ç¬¦ä¸²å†…éƒ¨åˆ†å—
	chunks := []string{
		`{"thought":"Let me`,
		` think about`,
		` this problem"}`}

	for _, chunk := range chunks {
		if err := parser.Write(chunk); err != nil {
			t.Fatalf("Failed to write chunk: %v", err)
		}
		time.Sleep(1 * time.Second)
	}

	// åœ¨å¢é‡æ¨¡å¼ä¸‹ï¼Œåº”è¯¥åªæ”¶åˆ°å¢é‡æ›´æ–°ï¼Œä¸åº”è¯¥æœ‰å®Œæ•´å­—ç¬¦ä¸²
	if len(incrementalResults) == 0 {
		t.Fatal("Expected at least one result")
	}

	// éªŒè¯æ²¡æœ‰å®Œæ•´å­—ç¬¦ä¸²è¢«å‘é€
	for _, result := range incrementalResults {
		if result == "Let me think about this problem" {
			t.Errorf("Incremental mode should not send complete string, but got: %q", result)
		}
	}

	// æµ‹è¯•ç´¯ç§¯æ¨¡å¼
	var cumulativeResults []string
	matcher2 := NewSimplePathMatcher()
	matcher2.On("thought", func(value interface{}, path []interface{}) {
		if str, ok := value.(string); ok {
			cumulativeResults = append(cumulativeResults, str)
			t.Logf("Cumulative result: %q", str)
		}
	})
	parser2 := NewStreamingJsonParser(matcher2, true, false)

	for _, chunk := range chunks {
		if err := parser2.Write(chunk); err != nil {
			t.Fatalf("Failed to write chunk: %v", err)
		}
	}

	if len(cumulativeResults) == 0 {
		t.Fatal("Expected at least one result in cumulative mode")
	}

	// åœ¨ç´¯ç§¯æ¨¡å¼ä¸‹ï¼Œæœ€åä¸€ä¸ªç»“æœåº”è¯¥æ˜¯å®Œæ•´çš„å­—ç¬¦ä¸²
	lastResult := cumulativeResults[len(cumulativeResults)-1]
	if lastResult != "Let me think about this problem" {
		t.Errorf("Expected final result to be complete string in cumulative mode, got: %q", lastResult)
	}

	// éªŒè¯å¢é‡æ¨¡å¼çš„ç»“æœæ•°é‡åº”è¯¥æ›´å°‘ï¼ˆå› ä¸ºé¿å…äº†é‡å¤å‘é€å®Œæ•´å­—ç¬¦ä¸²ï¼‰
	t.Logf("Incremental mode results: %d, Cumulative mode results: %d", len(incrementalResults), len(cumulativeResults))
	if len(incrementalResults) >= len(cumulativeResults) {
		t.Errorf("Expected incremental mode to have fewer results than cumulative mode, got incremental: %d, cumulative: %d", len(incrementalResults), len(cumulativeResults))
	}
}

// TestRealtimeIncrementalBugDemo ç®€åŒ–çš„æµ‹è¯•ï¼Œä¸“é—¨æ¼”ç¤ºå®æ—¶å¢é‡æ¨¡å¼çš„é—®é¢˜
func TestRealtimeIncrementalBugDemo(t *testing.T) {
	var results []interface{}
	matcher := NewSimplePathMatcher()

	// åŒ¹é…ç¬¬ä¸€ä¸ªæ•°ç»„å…ƒç´ çš„value
	matcher.On("items[0].value", func(value interface{}, path []interface{}) {
		results = append(results, value)
		t.Logf("Found value: %v at path: %v", value, path)
	})

	// ä½¿ç”¨å®æ—¶å¢é‡æ¨¡å¼
	parser := NewStreamingJsonParser(matcher, true, true)

	// ç®€å•çš„JSONæ•°ç»„
	jsonData := `{"items":[{"value":"hello"}]}`

	err := parser.Write(jsonData)
	if err != nil {
		t.Fatalf("Failed to parse JSON: %v", err)
	}

	err = parser.End()
	if err != nil {
		t.Fatalf("Failed to end parsing: %v", err)
	}

	// åœ¨å®æ—¶å¢é‡æ¨¡å¼ä¸‹ï¼Œ"hello"ä¼šè¢«æ‹†åˆ†æˆ5ä¸ªå­—ç¬¦å‘é€
	t.Logf("Total callbacks triggered: %d", len(results))
	t.Logf("All results: %v", results)

	if len(results) == 1 {
		t.Logf("SUCCESS: Got complete string value: %v", results[0])
	} else {
		t.Logf("EXPECTED BEHAVIOR: In realtime incremental mode, got %d character increments: %v", len(results), results)
	}
}

// TestArrayElementsMatchingInRealtimeIncremental éªŒè¯å®æ—¶å¢é‡æ¨¡å¼ä¸‹æ˜¯å¦èƒ½åŒ¹é…åˆ°æ‰€æœ‰æ•°ç»„å…ƒç´ 
func TestArrayElementsMatchingInRealtimeIncremental(t *testing.T) {
	var allMatches []struct {
		value interface{}
		path  []interface{}
	}
	matcher := NewSimplePathMatcher()

	// åŒ¹é…æ•°ç»„ä¸­æ‰€æœ‰å…ƒç´ çš„valueå­—æ®µ
	matcher.On("data.items[*].value", func(value interface{}, path []interface{}) {
		allMatches = append(allMatches, struct {
			value interface{}
			path  []interface{}
		}{value: value, path: append([]interface{}{}, path...)})
		t.Logf("Match: value='%v' at path=%v", value, path)
	})

	// ä½¿ç”¨å®æ—¶å¢é‡æ¨¡å¼
	parser := NewStreamingJsonParser(matcher, true, true)

	// åŒ…å«3ä¸ªæ•°ç»„å…ƒç´ çš„JSON
	jsonData := `{
		"data": {
			"items": [
				{"value": "first", "id": 1},
				{"value": "second", "id": 2},
				{"value": "third", "id": 3}
			]
		}
	}`

	err := parser.Write(jsonData)
	if err != nil {
		t.Fatalf("Failed to parse JSON: %v", err)
	}

	err = parser.End()
	if err != nil {
		t.Fatalf("Failed to end parsing: %v", err)
	}

	// åˆ†æåŒ¹é…ç»“æœ
	uniqueArrayIndices := make(map[int]bool)
	maxValuesByIndex := make(map[int]string)

	for _, match := range allMatches {
		if len(match.path) >= 3 {
			if arrayIndex, ok := match.path[2].(int); ok {
				uniqueArrayIndices[arrayIndex] = true
				// è®°å½•æ¯ä¸ªç´¢å¼•ä½ç½®çš„æœ€é•¿å€¼ï¼ˆæœ€å®Œæ•´çš„å€¼ï¼‰
				if str, ok := match.value.(string); ok {
					if len(str) > len(maxValuesByIndex[arrayIndex]) {
						maxValuesByIndex[arrayIndex] = str
					}
				}
			}
		}
	}

	t.Logf("Total matches: %d", len(allMatches))
	t.Logf("Unique array indices matched: %v", getKeys(uniqueArrayIndices))
	t.Logf("Max values by index: %v", maxValuesByIndex)

	// éªŒè¯æ˜¯å¦åŒ¹é…åˆ°äº†æ‰€æœ‰3ä¸ªæ•°ç»„å…ƒç´ 
	expectedIndices := []int{0, 1, 2}
	for _, expectedIndex := range expectedIndices {
		if !uniqueArrayIndices[expectedIndex] {
			t.Errorf("Missing array index %d in matched paths", expectedIndex)
		}
	}

	// éªŒè¯æ˜¯å¦æ‰¾åˆ°äº†é¢„æœŸçš„å€¼ï¼ˆå³ä½¿æ˜¯å¢é‡å½¢å¼ï¼‰
	expectedValues := map[int]string{0: "first", 1: "second", 2: "third"}
	allFound := true
	for index, expectedValue := range expectedValues {
		if maxValue, exists := maxValuesByIndex[index]; exists {
			if maxValue == expectedValue {
				t.Logf("âœ… Array index %d: found complete value '%s'", index, maxValue)
			} else {
				t.Logf("âš ï¸  Array index %d: found partial value '%s', expected '%s'", index, maxValue, expectedValue)
				allFound = false
			}
		} else {
			t.Errorf("âŒ Array index %d: no value found", index)
			allFound = false
		}
	}

	if len(uniqueArrayIndices) == 3 {
		t.Logf("âœ… SUCCESS: All 3 array elements were matched in realtime incremental mode")
		if allFound {
			t.Logf("âœ… All expected values were found (complete or partial)")
		} else {
			t.Logf("âš ï¸  Some values were only partially matched due to incremental nature")
		}
	} else {
		t.Errorf("âŒ Expected 3 array indices, got %d", len(uniqueArrayIndices))
	}
}

// TestRealtimeIncrementalArrayBehaviorSummary æ€»ç»“æ€§æµ‹è¯•ï¼šéªŒè¯å®æ—¶å¢é‡æ¨¡å¼ä¸‹æ•°ç»„è§£æçš„å®Œæ•´è¡Œä¸º
func TestRealtimeIncrementalArrayBehaviorSummary(t *testing.T) {
	t.Log("=== å®æ—¶å¢é‡æ¨¡å¼ä¸‹JSONæ•°ç»„è§£æè¡Œä¸ºéªŒè¯ ===")

	var allResults []interface{}
	var pathCounts map[string]int = make(map[string]int)
	matcher := NewSimplePathMatcher()

	// åŒ¹é…æ•°ç»„ä¸­æ‰€æœ‰å…ƒç´ çš„valueå­—æ®µ
	matcher.On("steps[*].name", func(value interface{}, path []interface{}) {
		allResults = append(allResults, value)
		pathStr := fmt.Sprintf("%v", path)
		pathCounts[pathStr]++
	})

	// ä½¿ç”¨å®æ—¶å¢é‡æ¨¡å¼
	parser := NewStreamingJsonParser(matcher, true, true)

	// åŒ…å«å¤šä¸ªæ•°ç»„å…ƒç´ çš„JSON
	jsonData := `{
    "id": "plan_001",
    "name": "Evaluation of AI in K-12 Education",
    "description": "A structured approach to evaluate the effectiveness and impact of AI technology in K-12 education.",
    "steps": [
        {
            "id": "step_1",
            "name": "Determine Decomposition Strategy",
            "description": "Analyze the complexity of the task and decide on the suitable decomposition strategy for the evaluation process.",
            "assigned_specialist": "DecompositionDecisionAgent",
            "priority": 1,
            "dependencies": [],
            "parameters": {}
        },
        {
            "id": "step_2",
            "name": "Decompose Evaluation Framework",
            "description": "Based on the determined strategy, decompose the overall evaluation framework into manageable sub-problems and identify their dependencies.",
            "assigned_specialist": "ProblemDecompositionAgent",
            "priority": 2,
            "dependencies": [
                "step_1"
            ],
            "parameters": {}
        }
    ]
}`

	err := parser.Write(jsonData)
	if err != nil {
		t.Fatalf("è§£æå¤±è´¥: %v", err)
	}

	err = parser.End()
	if err != nil {
		t.Fatalf("ç»“æŸè§£æå¤±è´¥: %v", err)
	}

	// åˆ†æç»“æœ
	uniqueIndices := make(map[int]bool)
	for pathStr := range pathCounts {
		// ä»è·¯å¾„å­—ç¬¦ä¸²ä¸­æå–æ•°ç»„ç´¢å¼•
		if strings.Contains(pathStr, "steps 0") {
			uniqueIndices[0] = true
		} else if strings.Contains(pathStr, "steps 1") {
			uniqueIndices[1] = true
		}
	}

	t.Logf("æ€»åŒ¹é…æ¬¡æ•°: %d", len(allResults))
	t.Logf("åŒ¹é…åˆ°çš„æ•°ç»„ç´¢å¼•: %v", getKeys(uniqueIndices))
	t.Logf("å„è·¯å¾„åŒ¹é…æ¬¡æ•°: %v", pathCounts)

	// éªŒè¯æ ¸å¿ƒé—®é¢˜çš„ç­”æ¡ˆ
	if len(uniqueIndices) == 2 {
		t.Log("âœ… æ ¸å¿ƒé—®é¢˜ç­”æ¡ˆï¼šå®æ—¶å¢é‡æ¨¡å¼ä¸‹èƒ½å¤Ÿæ­£å¸¸åŒ¹é…æ•°ç»„ç»“æ„ä¸­çš„æ‰€æœ‰å€¼")
		t.Logf("âœ… æ‰€æœ‰2ä¸ªæ•°ç»„å…ƒç´ ï¼ˆç´¢å¼•0ã€1ï¼‰éƒ½è¢«æˆåŠŸåŒ¹é…")
		t.Log("âœ… æ•°ç»„ç»“æ„è§£ææ­£å¸¸ï¼Œè·¯å¾„åŒ¹é…æ­£ç¡®")
		t.Log("")
		t.Log("ğŸ“ è¯´æ˜ï¼š")
		t.Log("   - å®æ—¶å¢é‡æ¨¡å¼çš„è®¾è®¡ç›®çš„å°±æ˜¯å°†å­—ç¬¦ä¸²æ‹†åˆ†æˆå•ä¸ªå­—ç¬¦è¿›è¡Œå¢é‡å‘é€")
		t.Log("   - è¿™ç§æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²å€¼ä¼šè§¦å‘å¤šæ¬¡å›è°ƒï¼ˆæ¯ä¸ªå­—ç¬¦ä¸€æ¬¡ï¼‰")
		t.Log("   - ä½†æ˜¯æ•°ç»„ç»“æ„çš„è§£æå’Œè·¯å¾„åŒ¹é…å®Œå…¨æ­£å¸¸")
		t.Log("   - æ‰€æœ‰æ•°ç»„å…ƒç´ éƒ½èƒ½è¢«æ­£ç¡®è¯†åˆ«å’ŒåŒ¹é…")
	} else {
		t.Errorf("âŒ é—®é¢˜ï¼šåªåŒ¹é…åˆ° %d ä¸ªæ•°ç»„å…ƒç´ ï¼ŒæœŸæœ› 2 ä¸ª", len(uniqueIndices))
	}

	// é¢å¤–éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æ¯ä¸ªæ•°ç»„å…ƒç´ éƒ½æœ‰å¤šæ¬¡åŒ¹é…ï¼ˆå› ä¸ºå­—ç¬¦ä¸²è¢«æ‹†åˆ†ï¼‰
	for i := 0; i < 2; i++ {
		pathPattern := fmt.Sprintf("steps %d", i)
		matchCount := 0
		for pathStr, count := range pathCounts {
			if strings.Contains(pathStr, pathPattern) {
				matchCount += count
			}
		}
		if matchCount > 1 {
			t.Logf("âœ… æ•°ç»„å…ƒç´  %d: è§¦å‘äº† %d æ¬¡åŒ¹é…ï¼ˆå­—ç¬¦ä¸²è¢«æ­£ç¡®æ‹†åˆ†ï¼‰", i, matchCount)
		} else {
			t.Logf("âš ï¸  æ•°ç»„å…ƒç´  %d: åªè§¦å‘äº† %d æ¬¡åŒ¹é…", i, matchCount)
		}
	}
}

// getKeys è·å–mapçš„æ‰€æœ‰é”®
func getKeys(m map[int]bool) []int {
	keys := make([]int, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}
